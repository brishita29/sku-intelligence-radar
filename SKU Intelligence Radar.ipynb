{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4471234,"sourceType":"datasetVersion","datasetId":1031},{"sourceId":12435068,"sourceType":"datasetVersion","datasetId":7843803},{"sourceId":12435079,"sourceType":"datasetVersion","datasetId":7843811},{"sourceId":12435121,"sourceType":"datasetVersion","datasetId":7843827},{"sourceId":12479920,"sourceType":"datasetVersion","datasetId":7874433}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Step 1: Setup and Package Imports","metadata":{"_uuid":"5566ff43-3781-4438-9a23-b9fedd650944","_cell_guid":"873a888c-82d4-44a9-9b40-632e326e102f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import duckdb  \nimport pandas as pd","metadata":{"_uuid":"22ddea43-315a-45ba-a7bc-04ab509591f4","_cell_guid":"d7835164-394c-47a3-b39f-27678ee2baf5","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-17T05:00:37.010633Z","iopub.execute_input":"2025-07-17T05:00:37.011336Z","iopub.status.idle":"2025-07-17T05:00:37.015628Z","shell.execute_reply.started":"2025-07-17T05:00:37.011308Z","shell.execute_reply":"2025-07-17T05:00:37.014547Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 2: Load and Preview Dataset","metadata":{"_uuid":"d6752a00-6634-4b36-8d73-5a91ef161824","_cell_guid":"eb2b9798-66f9-4603-9cc0-12c9132545f2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"##Step 1 : Load Dataset + Preview \nimport duckdb\nimport pandas as pd\n\n# Load and preview the dataset\nquery = \"\"\"\nSELECT * \nFROM '/kaggle/input/ecommerce-dataset/events.csv'\nLIMIT 5\n\"\"\"\nduckdb.query(query).df()","metadata":{"_uuid":"f5f010d3-d1bb-4f97-89f2-c33c4c6f00f9","_cell_guid":"3256d401-cf58-4c77-9d11-6e109ce75d05","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-17T03:59:47.129450Z","iopub.execute_input":"2025-07-17T03:59:47.130204Z","iopub.status.idle":"2025-07-17T03:59:47.256333Z","shell.execute_reply.started":"2025-07-17T03:59:47.130178Z","shell.execute_reply":"2025-07-17T03:59:47.255624Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 3: Dataset Size","metadata":{"_uuid":"67cd608f-5b25-468c-a324-46e503d265ae","_cell_guid":"69d5231c-5ac8-4bf0-bed5-3abdc7378346","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import duckdb\n\n# Correct way to run SQL query in Python\nduckdb.query(\"\"\"\n    SELECT COUNT(*) AS total_rows\n    FROM '/kaggle/input/ecommerce-dataset/events.csv'\n\"\"\").df()","metadata":{"_uuid":"13ec4371-5122-45df-b29a-fc0d34195e4c","_cell_guid":"770e406b-e057-4287-aeee-5bb1d65007c2","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-17T04:01:10.528626Z","iopub.execute_input":"2025-07-17T04:01:10.528966Z","iopub.status.idle":"2025-07-17T04:01:10.929830Z","shell.execute_reply.started":"2025-07-17T04:01:10.528938Z","shell.execute_reply":"2025-07-17T04:01:10.928805Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Unique Visitors and Items","metadata":{"_uuid":"dba9b1a2-89ff-4a2f-896d-e94df1450558","_cell_guid":"a8dd2feb-7189-424d-b2df-0170e7987788","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"duckdb.query(\"\"\"\n    SELECT \n        COUNT(DISTINCT visitorid) AS unique_visitors,\n        COUNT(DISTINCT itemid) AS unique_items\n    FROM '/kaggle/input/ecommerce-dataset/events.csv'\n\"\"\").df()","metadata":{"_uuid":"1ac4d391-d368-4c50-b7df-ea353ff3309b","_cell_guid":"e868e9b8-e63c-4431-bce2-f82b641ae362","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-17T04:01:26.294622Z","iopub.execute_input":"2025-07-17T04:01:26.294985Z","iopub.status.idle":"2025-07-17T04:01:26.986182Z","shell.execute_reply.started":"2025-07-17T04:01:26.294959Z","shell.execute_reply":"2025-07-17T04:01:26.985373Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Frequency of Event Types","metadata":{"_uuid":"65f4d73b-0f92-4bbb-b16b-ec4da52fa14a","_cell_guid":"0c62bb32-ac50-4cc8-a461-cf486eadfd29","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"duckdb.query(\"\"\"\n    SELECT event, COUNT(*) AS event_count\n    FROM '/kaggle/input/ecommerce-dataset/events.csv'\n    GROUP BY event\n    ORDER BY event_count DESC\n\"\"\").df()","metadata":{"_uuid":"83097307-370b-47e9-9483-4c8b3009b80b","_cell_guid":"d0e74c71-cff9-40cf-9eb5-59f663fc2c36","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-17T04:01:47.084198Z","iopub.execute_input":"2025-07-17T04:01:47.084518Z","iopub.status.idle":"2025-07-17T04:01:47.502535Z","shell.execute_reply.started":"2025-07-17T04:01:47.084494Z","shell.execute_reply":"2025-07-17T04:01:47.501680Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 4: Visualize Event Type Distribution","metadata":{"_uuid":"6b048410-3ad4-4af5-b51e-c002fbadc962","_cell_guid":"833407a3-eda3-4c9e-988f-5735bce97435","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Create the event distribution table\nevent_df = duckdb.query(\"\"\"\n    SELECT event, COUNT(*) AS event_count\n    FROM '/kaggle/input/ecommerce-dataset/events.csv'\n    GROUP BY event\n    ORDER BY event_count DESC\n\"\"\").df()","metadata":{"_uuid":"746c1931-cd7d-4a12-9431-583a6c4f894b","_cell_guid":"188ebad1-b4bd-45e6-b2d7-c35fbc102f80","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-17T04:38:21.923329Z","iopub.execute_input":"2025-07-17T04:38:21.923713Z","iopub.status.idle":"2025-07-17T04:38:22.359248Z","shell.execute_reply.started":"2025-07-17T04:38:21.923687Z","shell.execute_reply":"2025-07-17T04:38:22.358260Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 5: Timestamp to Date & Hour\nConvert epoch timestamps into readable dates and hours.","metadata":{"_uuid":"b220bf67-ba8e-4f6f-9989-7157d9f99964","_cell_guid":"fa83c83c-83e5-4fb0-b086-5b0ee68eccf5","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Extract timestamp → readable format\nduckdb.query(\"\"\"\n    SELECT \n        timestamp,\n        TO_TIMESTAMP(timestamp / 1000) AS event_time,\n        STRFTIME(TO_TIMESTAMP(timestamp / 1000), '%Y-%m-%d') AS event_date,\n        STRFTIME(TO_TIMESTAMP(timestamp / 1000), '%H') AS hour,\n        event\n    FROM '/kaggle/input/ecommerce-dataset/events.csv'\n    LIMIT 100000\n\"\"\").df().head()","metadata":{"_uuid":"0bf95d0f-5760-4f4d-8e3b-a74820242859","_cell_guid":"466791d2-10fa-4a14-ac09-0a5993f620d9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-17T04:02:49.843850Z","iopub.execute_input":"2025-07-17T04:02:49.844214Z","iopub.status.idle":"2025-07-17T04:02:50.199891Z","shell.execute_reply.started":"2025-07-17T04:02:49.844189Z","shell.execute_reply":"2025-07-17T04:02:50.198954Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 6: Daily Event Trends\nVisualize how user engagement changes across days.","metadata":{"_uuid":"26b2a2df-0d71-4f2f-85c1-ce906b8d3675","_cell_guid":"ef41fb6f-59fc-4b02-b03a-26e4f1a0a7fa","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"daily_df = duckdb.query(\"\"\"\n    SELECT \n        STRFTIME(TO_TIMESTAMP(timestamp / 1000), '%Y-%m-%d') AS event_date,\n        COUNT(*) AS total_events\n    FROM '/kaggle/input/ecommerce-dataset/events.csv'\n    GROUP BY event_date\n    ORDER BY event_date\n\"\"\").df()\n\n# Plot\nplt.figure(figsize=(10, 4))\nplt.plot(daily_df['event_date'], daily_df['total_events'], color='purple')\nplt.xticks(rotation=45)\nplt.title('Total Events per Day')\nplt.xlabel('Date')\nplt.ylabel('Number of Events')\nplt.grid(True, linestyle='--', alpha=0.6)\nplt.tight_layout()\nplt.show()","metadata":{"_uuid":"c2e5b11e-eb59-4fcb-93da-912303070059","_cell_guid":"4f8c5e29-2ae7-4740-baff-a20b52b56dea","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-17T04:03:06.745538Z","iopub.execute_input":"2025-07-17T04:03:06.745847Z","iopub.status.idle":"2025-07-17T04:03:08.847858Z","shell.execute_reply.started":"2025-07-17T04:03:06.745824Z","shell.execute_reply":"2025-07-17T04:03:08.846801Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 7: Hourly Engagement Pattern\nPeak browsing times throughout the day.","metadata":{"_uuid":"ce98bde8-1d8e-4a7b-a828-d10d36375e46","_cell_guid":"2d2e5dec-4db2-4e46-a15d-74620453fe6d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Query hourly activity pattern\nhourly_df = duckdb.query(\"\"\"\n    SELECT \n        STRFTIME(TO_TIMESTAMP(timestamp / 1000), '%H') AS hour,\n        COUNT(*) AS total_events\n    FROM '/kaggle/input/ecommerce-dataset/events.csv'\n    GROUP BY hour\n    ORDER BY hour\n\"\"\").df()\n\n# Convert hour to int for sorting\nhourly_df['hour'] = hourly_df['hour'].astype(int)\n\n# Plot\nplt.figure(figsize=(8, 4))\nplt.plot(hourly_df['hour'], hourly_df['total_events'], marker='o', color='darkorange', linewidth=2)\nplt.title('🕐 Hourly User Activity Trend', fontsize=14)\nplt.xlabel('Hour of Day (24h)')\nplt.ylabel('Number of Events')\nplt.xticks(range(0, 24))\nplt.grid(True, linestyle='--', alpha=0.6)\nplt.tight_layout()\nplt.show()","metadata":{"_uuid":"64ba2db0-e79b-4987-9d72-46f7a2af767a","_cell_guid":"f5cc836f-3a23-4cec-b871-7daab70e9529","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-17T04:04:08.929270Z","iopub.execute_input":"2025-07-17T04:04:08.929611Z","iopub.status.idle":"2025-07-17T04:04:10.241750Z","shell.execute_reply.started":"2025-07-17T04:04:08.929586Z","shell.execute_reply":"2025-07-17T04:04:10.240846Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 8: Funnel Metrics per Product\n\nWe calculate conversion metrics for each product:\n- Views → Cart\n- Cart → Purchase\n- Views → Purchase","metadata":{"_uuid":"ac30c176-7820-4489-b526-2fb841b4d12e","_cell_guid":"4c614781-c540-465a-ad6f-641285d4c89e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Aggregate funnel metrics per itemid\nfunnel_df = duckdb.query(\"\"\"\n    SELECT \n        itemid,\n        SUM(CASE WHEN event = 'view' THEN 1 ELSE 0 END) AS views,\n        SUM(CASE WHEN event = 'addtocart' THEN 1 ELSE 0 END) AS add_to_cart,\n        SUM(CASE WHEN event = 'transaction' THEN 1 ELSE 0 END) AS purchases\n    FROM '/kaggle/input/ecommerce-dataset/events.csv'\n    GROUP BY itemid\n\"\"\").df()\n\n# Calculate funnel ratios\nfunnel_df['view_to_cart'] = funnel_df['add_to_cart'] / funnel_df['views']\nfunnel_df['cart_to_buy'] = funnel_df['purchases'] / funnel_df['add_to_cart']\nfunnel_df['view_to_buy'] = funnel_df['purchases'] / funnel_df['views']\n\n# Replace infinite or NaN values\nfunnel_df.replace([float('inf'), -float('inf')], pd.NA, inplace=True)\nfunnel_df.dropna(subset=['view_to_cart', 'cart_to_buy', 'view_to_buy'], inplace=True)\n\n# Preview top results\nfunnel_df.head()","metadata":{"_uuid":"70fc7082-e05f-48cf-89ef-7a99a21403a5","_cell_guid":"2c71533c-ae74-4ff5-8be2-dbf4d33704fb","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-17T04:04:33.785752Z","iopub.execute_input":"2025-07-17T04:04:33.786932Z","iopub.status.idle":"2025-07-17T04:04:34.660446Z","shell.execute_reply.started":"2025-07-17T04:04:33.786810Z","shell.execute_reply":"2025-07-17T04:04:34.659640Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 9: Filter High-View SKUs","metadata":{"_uuid":"a8405f57-796e-4cd9-90fa-cb842edee188","_cell_guid":"7d1be367-482c-4f69-9d0b-ce1f8c8428e8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"query = \"\"\"\nSELECT\n    itemid,\n    SUM(CASE WHEN event = 'view' THEN 1 ELSE 0 END) AS views,\n    SUM(CASE WHEN event = 'addtocart' THEN 1 ELSE 0 END) AS add_to_cart,\n    SUM(CASE WHEN event = 'transaction' THEN 1 ELSE 0 END) AS purchases\nFROM '/kaggle/input/ecommerce-dataset/events.csv'\nGROUP BY itemid\nHAVING views > 100\nORDER BY views DESC\n\"\"\"\n\nfunnel_df = duckdb.query(query).df()\nfunnel_df.head()","metadata":{"_uuid":"93c5ed4d-a6dc-4e39-994c-c167cc7882f6","_cell_guid":"d0a0cea4-2755-4a1c-b32a-e2645b7407a4","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-15T17:52:19.070189Z","iopub.execute_input":"2025-07-15T17:52:19.071088Z","iopub.status.idle":"2025-07-15T17:52:19.756530Z","shell.execute_reply.started":"2025-07-15T17:52:19.071027Z","shell.execute_reply":"2025-07-15T17:52:19.755762Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 10: Calculate Funnel Conversion Rates for High-View SKUs","metadata":{"_uuid":"31dc00d7-2943-4040-8c65-17e425db5633","_cell_guid":"b849c0ee-50a8-4389-8e0b-a9a3a67b4654","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"funnel_df['view_to_cart'] = funnel_df['add_to_cart'] / funnel_df['views']\nfunnel_df['cart_to_buy'] = funnel_df['purchases'] / funnel_df['add_to_cart']\nfunnel_df['view_to_buy'] = funnel_df['purchases'] / funnel_df['views']\n\n# Replace inf or NaNs from division by 0\nfunnel_df.replace([float('inf'), -float('inf')], 0, inplace=True)\nfunnel_df.fillna(0, inplace=True)\n\nfunnel_df.head(10)","metadata":{"_uuid":"c91c5a57-3313-449b-94a5-34bf6582aed3","_cell_guid":"7cbb9d15-f3ed-4215-9540-9cb0dca8beb9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:21:34.179773Z","iopub.execute_input":"2025-07-10T22:21:34.180112Z","iopub.status.idle":"2025-07-10T22:21:34.206023Z","shell.execute_reply.started":"2025-07-10T22:21:34.180087Z","shell.execute_reply":"2025-07-10T22:21:34.205089Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 11: Simulate Price and Cost for Each SKU","metadata":{"_uuid":"8271d1ce-a354-42e6-8534-a6250fd7e81a","_cell_guid":"73c8c8af-dc27-44bd-bb42-a0f6f7f584ed","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import numpy as np\n\n# Simulate margin info based on funnel_df itemids\nmargin_df = funnel_df[['itemid']].copy()\nnp.random.seed(42)\n\n# Simulated price and cost\nmargin_df['price'] = np.random.uniform(20, 100, size=len(margin_df))\nmargin_df['cost'] = margin_df['price'] * np.random.uniform(0.5, 0.85, size=len(margin_df))\n\nmargin_df['price'] = margin_df['price'].round(2)\nmargin_df['cost'] = margin_df['cost'].round(2)\n\nmargin_df.head()","metadata":{"_uuid":"2e8f9dae-3e81-49db-9adf-5234164ba5b6","_cell_guid":"cb0515fa-431e-4381-8e03-725e0f749626","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:21:37.307909Z","iopub.execute_input":"2025-07-10T22:21:37.308265Z","iopub.status.idle":"2025-07-10T22:21:37.338732Z","shell.execute_reply.started":"2025-07-10T22:21:37.308240Z","shell.execute_reply":"2025-07-10T22:21:37.337539Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 12: Merge Funnel & Margin Data + Flag Profit Erosion","metadata":{"_uuid":"437edff2-bf54-41c9-8091-582066588262","_cell_guid":"1570adfd-d9f5-40db-858d-f0cd721f47a4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import pandas as pd\n\n# Now calculate margin per unit\nmargin_df['margin_per_unit'] = margin_df['price'] - margin_df['cost']\n\n# Merge with funnel data\nmerged_df = pd.merge(funnel_df, margin_df, on='itemid', how='left')\n\n# Calculate gross margin\nmerged_df['gross_margin'] = merged_df['margin_per_unit'] * merged_df['purchases']\n\n# Flag erosion\nmerged_df['erosion_flag'] = ((merged_df['views'] > 1000) &\n                             (merged_df['view_to_buy'] < 0.01) &\n                             (merged_df['margin_per_unit'] > 10)).astype(int)\n\nmerged_df.head(10)","metadata":{"_uuid":"fc2c03ea-3a9a-4c29-8d9d-dd6d63a57153","_cell_guid":"3ead6e2b-803c-437c-b2e7-7fcf6a2dff17","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:21:40.171478Z","iopub.execute_input":"2025-07-10T22:21:40.172755Z","iopub.status.idle":"2025-07-10T22:21:40.215564Z","shell.execute_reply.started":"2025-07-10T22:21:40.172703Z","shell.execute_reply":"2025-07-10T22:21:40.214365Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 13: Export Dataset","metadata":{}},{"cell_type":"code","source":"merged_df.to_csv('profit_erosion_sku_analysis.csv', index=False)","metadata":{"_uuid":"1bee71a8-cacb-4a11-a451-13ed2202c1df","_cell_guid":"c53d3583-67de-43ef-b8f2-ecf231530eb9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:21:48.274959Z","iopub.execute_input":"2025-07-10T22:21:48.275302Z","iopub.status.idle":"2025-07-10T22:21:48.336929Z","shell.execute_reply.started":"2025-07-10T22:21:48.275279Z","shell.execute_reply":"2025-07-10T22:21:48.335812Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 14: Identify Top Grossing SKUs","metadata":{}},{"cell_type":"code","source":"duckdb.query(\"\"\"\n    SELECT itemid, purchases, gross_margin, margin_per_unit\n    FROM df\n    WHERE purchases > 10\n    ORDER BY gross_margin DESC\n    LIMIT 10\n\"\"\").df()","metadata":{"_uuid":"dbd16cbc-569f-49dd-ab8d-8e1570c0c06e","_cell_guid":"062d9ee6-2dca-4540-8a9b-86b9bb7aea03","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:21:58.813731Z","iopub.execute_input":"2025-07-10T22:21:58.814183Z","iopub.status.idle":"2025-07-10T22:21:58.839865Z","shell.execute_reply.started":"2025-07-10T22:21:58.814152Z","shell.execute_reply":"2025-07-10T22:21:58.838527Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 15: Identify High-Traffic SKUs with Zero Purchases","metadata":{}},{"cell_type":"code","source":"duckdb.query(\"\"\"\n    SELECT itemid, views, purchases, view_to_buy, erosion_flag\n    FROM df\n    WHERE purchases = 0 AND views > 1000\n    ORDER BY views DESC\n\"\"\").df()","metadata":{"_uuid":"970495d7-b8d0-4e9a-8ce1-2e5dcd91b9de","_cell_guid":"533c2ad3-e4f7-44a4-952f-306a68f9fb7a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:22:01.799594Z","iopub.execute_input":"2025-07-10T22:22:01.800477Z","iopub.status.idle":"2025-07-10T22:22:01.823915Z","shell.execute_reply.started":"2025-07-10T22:22:01.800443Z","shell.execute_reply":"2025-07-10T22:22:01.822632Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 16: SKUs with Maximum Profit Erosion","metadata":{}},{"cell_type":"code","source":"duckdb.query(\"\"\"\n    SELECT itemid, views, purchases, view_to_buy, margin_per_unit, gross_margin\n    FROM df\n    WHERE erosion_flag = 1\n    ORDER BY margin_per_unit DESC\n\"\"\").df()","metadata":{"_uuid":"14824702-ae2e-4d15-9885-891367d58536","_cell_guid":"b9b3b3d8-cce7-435f-b07a-ed666fe5a365","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:22:04.804044Z","iopub.execute_input":"2025-07-10T22:22:04.804452Z","iopub.status.idle":"2025-07-10T22:22:04.827150Z","shell.execute_reply.started":"2025-07-10T22:22:04.804425Z","shell.execute_reply":"2025-07-10T22:22:04.825938Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 17: Erosion Score — Prioritize Most Critical SKUs","metadata":{}},{"cell_type":"code","source":"# Normalize helper\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Copy to avoid modifying source\nscore_df = merged_df.copy()\n\n\n# Fill NA values just in case\nscore_df.fillna(0, inplace=True)\n\n# Normalize the key metrics to 0–1\nscaler = MinMaxScaler()\n\nscore_df['norm_views'] = scaler.fit_transform(score_df[['views']])\nscore_df['norm_view_to_buy'] = 1 - scaler.fit_transform(score_df[['view_to_buy']])  # invert\nscore_df['norm_margin'] = scaler.fit_transform(score_df[['margin_per_unit']])\nscore_df['norm_age'] = scaler.fit_transform(score_df[['views']])  # assume views = time exposed\nscore_df['cart_no_purchase'] = ((score_df['add_to_cart'] > 0) & (score_df['purchases'] == 0)).astype(int)\n\n# Weighted Score\nscore_df['erosion_score'] = (\n    score_df['norm_views'] * 0.35 +\n    score_df['norm_view_to_buy'] * 0.25 +\n    score_df['norm_margin'] * 0.25 +\n    score_df['cart_no_purchase'] * 0.15\n) * 100\n\n# Cleaned output\nscored_products = score_df[['itemid', 'views', 'purchases', 'margin_per_unit', 'view_to_buy', 'erosion_score']]\nscored_products = scored_products.sort_values(by='erosion_score', ascending=False)\n\nscored_products.head(10)","metadata":{"_uuid":"2eb4ae82-a2ba-4118-96e9-8c91715ca1b4","_cell_guid":"af4d3657-9186-4356-9954-2bbeb824fafb","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:22:08.217036Z","iopub.execute_input":"2025-07-10T22:22:08.218071Z","iopub.status.idle":"2025-07-10T22:22:08.828078Z","shell.execute_reply.started":"2025-07-10T22:22:08.218026Z","shell.execute_reply":"2025-07-10T22:22:08.826884Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 18: Estimate Potential Margin Recovery","metadata":{}},{"cell_type":"code","source":"# Import margin per unit from the correct dataset\nmerged_margin_df = merged_df[['itemid', 'margin_per_unit']]\ntop_erosion_df = pd.merge(top_erosion_df, merged_margin_df, on='itemid', how='left')\n\n# Now calculate margin recovered\ntop_erosion_df['potential_margin_recovered'] = top_erosion_df['potential_extra_purchases'] * top_erosion_df['margin_per_unit']\n\n# Final view\nloss_impact_df = top_erosion_df[['itemid', 'views', 'purchases', 'margin_per_unit',\n                                 'potential_extra_purchases', 'potential_margin_recovered']].sort_values(\n    by='potential_margin_recovered', ascending=False)\n\nloss_impact_df.head(10)","metadata":{"_uuid":"29c471f1-a7e7-4197-ab1f-78cb6ed69763","_cell_guid":"b35ca189-1f5b-4363-864b-69aad8b498cd","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:22:13.534726Z","iopub.execute_input":"2025-07-10T22:22:13.535265Z","iopub.status.idle":"2025-07-10T22:22:13.594809Z","shell.execute_reply.started":"2025-07-10T22:22:13.535238Z","shell.execute_reply":"2025-07-10T22:22:13.593342Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 19: Erosion Tagging for Qualitative Diagnosis","metadata":{}},{"cell_type":"code","source":"# Add tags to score_df (your erosion dataset)\n\ndef generate_tag(row):\n    if row['view_to_buy'] < 0.001:\n        return 'Zero Conversion'\n    elif row['view_to_buy'] < 0.005:\n        return 'Low Conversion'\n    elif row['view_to_buy'] > 0.05 and row['margin_per_unit'] > 20:\n        return 'High Margin, Moderate Conversion'\n    elif row['margin_per_unit'] > 25 and row['purchases'] == 0:\n        return 'High Margin No Sales'\n    elif row['views'] > 3000 and row['add_to_cart'] == 0:\n        return 'Viewed but Ignored'\n    else:\n        return 'Unclear'\n\nscore_df['erosion_tag'] = score_df.apply(generate_tag, axis=1)","metadata":{"_uuid":"215fa646-a844-43fa-8407-503aadc7cbe1","_cell_guid":"fbd27331-a49b-493c-abb8-6be45363f7c2","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:22:22.853322Z","iopub.execute_input":"2025-07-10T22:22:22.854525Z","iopub.status.idle":"2025-07-10T22:22:22.905352Z","shell.execute_reply.started":"2025-07-10T22:22:22.854493Z","shell.execute_reply":"2025-07-10T22:22:22.904092Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 20: Recommend Actionable Strategies Based on Tags","metadata":{}},{"cell_type":"code","source":"def suggest_strategy(tag):\n    if tag == 'Zero Conversion':\n        return 'Investigate PDP issues / Reposition listing'\n    elif tag == 'Low Conversion':\n        return 'Price test or update visuals'\n    elif tag == 'High Margin No Sales':\n        return 'Run micro discount pilot or bundle'\n    elif tag == 'Viewed but Ignored':\n        return 'Audit product placement / Search result position'\n    else:\n        return 'Needs manual deep dive'\n\nscore_df['strategy'] = score_df['erosion_tag'].apply(suggest_strategy)","metadata":{"_uuid":"1e63becd-a06a-4039-afa9-177e38e8e3fb","_cell_guid":"019075be-576b-4d13-8c22-ee00782054f7","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:22:26.222680Z","iopub.execute_input":"2025-07-10T22:22:26.223028Z","iopub.status.idle":"2025-07-10T22:22:26.231322Z","shell.execute_reply.started":"2025-07-10T22:22:26.223002Z","shell.execute_reply":"2025-07-10T22:22:26.229901Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 21: Final Strategic Recommendation Sheet","metadata":{}},{"cell_type":"code","source":"final_recommendation_df = score_df.sort_values(by='erosion_score', ascending=False)[\n    ['itemid', 'views', 'purchases', 'margin_per_unit', 'view_to_buy', 'erosion_score', 'erosion_tag', 'strategy']\n].head(15)\n\nfinal_recommendation_df.head(15)","metadata":{"_uuid":"f45ed938-6091-4d62-b303-2c594c2c0f22","_cell_guid":"ece5009e-8197-418b-b3a9-737b9c019f6b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:22:29.529750Z","iopub.execute_input":"2025-07-10T22:22:29.530137Z","iopub.status.idle":"2025-07-10T22:22:29.552963Z","shell.execute_reply.started":"2025-07-10T22:22:29.530113Z","shell.execute_reply":"2025-07-10T22:22:29.551517Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 22: Establish Conversion Benchmark  ","metadata":{}},{"cell_type":"code","source":"benchmark_rate = merged_df['view_to_buy'].quantile(0.90)\nprint(f\"Benchmark View-to-Buy Rate: {benchmark_rate:.4f}\")","metadata":{"_uuid":"4de3d5a5-ef31-4b01-ae12-f16d5e2c60e8","_cell_guid":"e4f29e8d-0dd0-49e8-b526-e3c46aaaf8d0","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:23:06.934369Z","iopub.execute_input":"2025-07-10T22:23:06.934836Z","iopub.status.idle":"2025-07-10T22:23:06.946443Z","shell.execute_reply.started":"2025-07-10T22:23:06.934799Z","shell.execute_reply":"2025-07-10T22:23:06.945035Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 23: Estimate Potential Extra Purchases  ","metadata":{}},{"cell_type":"code","source":"merged_df['potential_extra_purchases'] = (\n    (merged_df['views'] * benchmark_rate) - merged_df['purchases']\n).clip(lower=0)","metadata":{"_uuid":"9eefdbda-f958-405b-8e03-2ccbc2886964","_cell_guid":"0c49588a-d731-48a8-8491-e0edf9cb0964","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:23:09.035018Z","iopub.execute_input":"2025-07-10T22:23:09.035336Z","iopub.status.idle":"2025-07-10T22:23:09.043052Z","shell.execute_reply.started":"2025-07-10T22:23:09.035313Z","shell.execute_reply":"2025-07-10T22:23:09.042207Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 24: Calculate Potential Margin Recovered  ","metadata":{}},{"cell_type":"code","source":"# Step 3: Calculate potential margin recovered\nmerged_df['potential_margin_recovered'] = (\n    merged_df['potential_extra_purchases'] * merged_df['margin_per_unit']\n)","metadata":{"_uuid":"d839bb89-cc14-4585-9044-7760f04e5e01","_cell_guid":"3f7456bd-59d8-4525-801a-b76022f4fc6e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:23:11.053860Z","iopub.execute_input":"2025-07-10T22:23:11.054171Z","iopub.status.idle":"2025-07-10T22:23:11.060366Z","shell.execute_reply.started":"2025-07-10T22:23:11.054148Z","shell.execute_reply":"2025-07-10T22:23:11.059495Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 25: Identify Top Erosion SKUs with High Recovery Potential  ","metadata":{}},{"cell_type":"code","source":"# Step 4: Filter for top erosion cases with potential upside\nrecovery_df = merged_df[merged_df['erosion_flag'] == 1].copy()\n\ntop_recovery = recovery_df[[\n    'itemid', 'views', 'purchases', 'margin_per_unit',\n    'view_to_buy', 'potential_extra_purchases', 'potential_margin_recovered'\n]].sort_values(by='potential_margin_recovered', ascending=False).head(15)\n\ntop_recovery","metadata":{"_uuid":"c7cfff99-709e-4cb6-8d0d-864d12fa39f7","_cell_guid":"50aafb74-a564-40a2-ac1a-622aabfe6c1b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:23:13.826837Z","iopub.execute_input":"2025-07-10T22:23:13.827684Z","iopub.status.idle":"2025-07-10T22:23:13.851447Z","shell.execute_reply.started":"2025-07-10T22:23:13.827649Z","shell.execute_reply":"2025-07-10T22:23:13.850263Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 26: Smart Erosion Score – Advanced Prioritization  ","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\n# Copy the merged dataframe\nscore_df = merged_df.copy()\n\n# Fill any missing values\nscore_df.fillna(0, inplace=True)\n\n# Flag: Cart Added but No Purchase\nscore_df['cart_no_purchase'] = ((score_df['add_to_cart'] > 0) & (score_df['purchases'] == 0)).astype(int)\n\n# Initialize scaler\nscaler = MinMaxScaler()\n\n# Create normalized columns\nscore_df['norm_views'] = scaler.fit_transform(score_df[['views']])\nscore_df['norm_view_to_buy'] = 1 - scaler.fit_transform(score_df[['view_to_buy']])  # invert\nscore_df['norm_unit_margin'] = scaler.fit_transform(score_df[['margin_per_unit']])\nscore_df['norm_gross_margin'] = 1 - scaler.fit_transform(score_df[['gross_margin']])  # invert\n\n# Smart erosion score (real-world weights)\nscore_df['smart_erosion_score'] = (\n    score_df['norm_views'] * 0.30 +\n    score_df['norm_view_to_buy'] * 0.30 +\n    score_df['norm_unit_margin'] * 0.20 +\n    score_df['norm_gross_margin'] * 0.10 +\n    score_df['cart_no_purchase'] * 0.10\n) * 100\n\n# Top at-risk products\ntop_smart_erosion = score_df[[\n    'itemid', 'views', 'purchases', 'margin_per_unit', 'gross_margin', \n    'view_to_buy', 'smart_erosion_score'\n]].sort_values(by='smart_erosion_score', ascending=False).head(15)\n\ntop_smart_erosion.reset_index(drop=True, inplace=True)\ntop_smart_erosion","metadata":{"_uuid":"0edf0277-4369-458f-a9e4-c2a9a6ea87c1","_cell_guid":"a1f26a28-36bf-4b22-a4d9-051f420d1ea4","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:23:16.821191Z","iopub.execute_input":"2025-07-10T22:23:16.821573Z","iopub.status.idle":"2025-07-10T22:23:16.864914Z","shell.execute_reply.started":"2025-07-10T22:23:16.821547Z","shell.execute_reply":"2025-07-10T22:23:16.863884Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 27: Benchmark Conversion Rate  ","metadata":{}},{"cell_type":"code","source":"# 90th percentile view-to-buy conversion rate across all SKUs\nbenchmark_rate = merged_df['view_to_buy'].quantile(0.90)\nprint(f\"Benchmark View-to-Buy Rate: {benchmark_rate:.4f}\")","metadata":{"_uuid":"4f14a72e-3474-42fb-b1dc-bef7384459ae","_cell_guid":"d02490f4-c667-4885-a4eb-d59086ea3f9f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:23:21.094140Z","iopub.execute_input":"2025-07-10T22:23:21.094474Z","iopub.status.idle":"2025-07-10T22:23:21.101632Z","shell.execute_reply.started":"2025-07-10T22:23:21.094450Z","shell.execute_reply":"2025-07-10T22:23:21.100594Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 28: Estimate Potential Extra Purchases  ","metadata":{}},{"cell_type":"code","source":"# Calculate the expected purchases at benchmark conversion\nmerged_df['expected_purchases'] = merged_df['views'] * benchmark_rate\n\n# Calculate potential extra purchases\nmerged_df['potential_extra_purchases'] = merged_df['expected_purchases'] - merged_df['purchases']\nmerged_df['potential_extra_purchases'] = merged_df['potential_extra_purchases'].apply(lambda x: max(x, 0))  # avoid negatives","metadata":{"_uuid":"93178730-15b2-4bf4-b3c2-4341afe0f673","_cell_guid":"0e5d0127-9fb9-4a52-8fc7-5e1553e6438c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:23:23.653517Z","iopub.execute_input":"2025-07-10T22:23:23.653808Z","iopub.status.idle":"2025-07-10T22:23:23.664477Z","shell.execute_reply.started":"2025-07-10T22:23:23.653789Z","shell.execute_reply":"2025-07-10T22:23:23.663186Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 29: Identify High-Upside SKUs  ","metadata":{}},{"cell_type":"code","source":"uplift_df = merged_df[\n    ['itemid', 'views', 'purchases', 'margin_per_unit', 'view_to_buy', 'potential_extra_purchases', 'potential_margin_recovered']\n].sort_values(by='potential_margin_recovered', ascending=False)\n\nuplift_df.head(10)","metadata":{"_uuid":"07ca94c8-b600-4c4b-9c7c-4bec2e17ecfa","_cell_guid":"1b43158a-4e25-48c5-98f6-2d7afcc15ee9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:23:26.110692Z","iopub.execute_input":"2025-07-10T22:23:26.111009Z","iopub.status.idle":"2025-07-10T22:23:26.131896Z","shell.execute_reply.started":"2025-07-10T22:23:26.110984Z","shell.execute_reply":"2025-07-10T22:23:26.130792Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 30: Uplift Simulation — Strategic Recovery Scenarios","metadata":{}},{"cell_type":"code","source":"# Define benchmark uplift targets\np90_rate = merged_df['view_to_buy'].quantile(0.90)\ntop_1p_rate = merged_df['view_to_buy'].quantile(0.99)\n\n# Assume current rate uplift by +50% for Scenario B\ndef uplift_simulator(df):\n    df = df.copy()\n    \n    df['uplift_A'] = p90_rate\n    df['uplift_B'] = df['view_to_buy'] * 1.5\n    df['uplift_C'] = top_1p_rate\n    \n    for col in ['uplift_A', 'uplift_B', 'uplift_C']:\n        df[f'expected_extra_purchases_{col[-1]}'] = (df[col] - df['view_to_buy']) * df['views']\n        df[f'recovered_margin_{col[-1]}'] = df[f'expected_extra_purchases_{col[-1]}'] * df['margin_per_unit']\n    \n    return df[[\n        'itemid', 'views', 'purchases', 'margin_per_unit', 'view_to_buy',\n        'expected_extra_purchases_A', 'recovered_margin_A',\n        'expected_extra_purchases_B', 'recovered_margin_B',\n        'expected_extra_purchases_C', 'recovered_margin_C'\n    ]]\n\n# Run simulator on top erosion SKUs\nuplift_df = uplift_simulator(top_erosion_df)\nuplift_df.head(10)","metadata":{"_uuid":"00ed4068-d77e-4c21-b720-bd83dec75521","_cell_guid":"c167f771-ca97-48f8-b5c3-37c0d5cb20e0","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:23:29.607536Z","iopub.execute_input":"2025-07-10T22:23:29.607851Z","iopub.status.idle":"2025-07-10T22:23:29.631041Z","shell.execute_reply.started":"2025-07-10T22:23:29.607829Z","shell.execute_reply":"2025-07-10T22:23:29.629494Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 31: Priority Action Tags Based on Recovery Potential","metadata":{}},{"cell_type":"code","source":"final_df = uplift_df.copy()\n\ndef tag_priority_action(row):\n    if row['recovered_margin_A'] >= 3000:\n        return '🔴 Critical | Reposition SKU + Fix PDP immediately'\n    elif row['recovered_margin_A'] >= 1000:\n        return '🟠 High | A/B test offer / urgency CTA'\n    elif row['recovered_margin_A'] >= 500:\n        return '🟡 Medium | Bundle or reposition in category'\n    else:\n        return '⚪ Low | Deprioritize or test seasonally'\n\nfinal_df['action_priority'] = final_df.apply(tag_priority_action, axis=1)\n\n# Preview result\nfinal_df[['itemid', 'recovered_margin_A', 'action_priority']].head(10)","metadata":{"_uuid":"3e0c8333-9d7b-4bb1-8431-c343d6b64b8b","_cell_guid":"2af8edd7-b152-4dc5-a62e-6b771ded270b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:23:36.054615Z","iopub.execute_input":"2025-07-10T22:23:36.055060Z","iopub.status.idle":"2025-07-10T22:23:36.106340Z","shell.execute_reply.started":"2025-07-10T22:23:36.055025Z","shell.execute_reply":"2025-07-10T22:23:36.104764Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 30: Actionable Promo Strategy Recommendation","metadata":{}},{"cell_type":"code","source":"def recommend_action(row):\n    # Kill if zero purchases and low recovery potential\n    if row['purchases_x'] == 0 and row['max_recovery'] < 300:\n        return '❌ Kill SKU'\n    \n    # Recommend promo cut if recovery is good but performance is weak\n    elif row['max_recovery'] >= 300 and row['purchases_x'] < 5:\n        return '🔁 Cut Promo (' + row['best_scenario'].split('_')[-1] + ')'\n    \n    # Keep if purchases decent or promo benefit is marginal\n    else:\n        return '✅ Keep'","metadata":{"_uuid":"cf637ddd-10c8-4c8c-b7a9-8020b86c052f","_cell_guid":"8541a100-bb5e-490c-b716-5c4a69462da3","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:40:13.650278Z","iopub.execute_input":"2025-07-10T22:40:13.650669Z","iopub.status.idle":"2025-07-10T22:40:13.657558Z","shell.execute_reply.started":"2025-07-10T22:40:13.650645Z","shell.execute_reply":"2025-07-10T22:40:13.656378Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"merged_df['action'] = merged_df.apply(recommend_action, axis=1)","metadata":{"_uuid":"96423cb6-ba2e-445a-9a42-dbc99c2aa149","_cell_guid":"a70e3377-35e0-4abf-a585-8482a7dfe6a0","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:40:22.296689Z","iopub.execute_input":"2025-07-10T22:40:22.297032Z","iopub.status.idle":"2025-07-10T22:40:22.305834Z","shell.execute_reply.started":"2025-07-10T22:40:22.297008Z","shell.execute_reply":"2025-07-10T22:40:22.304716Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 31: Assign Final Promo-Based Action to Each SKU","metadata":{}},{"cell_type":"code","source":"final_actions = merged_df[[\n    'itemid', 'views_x', 'purchases_x', 'margin_per_unit_x',\n    'max_recovery', 'best_scenario', 'action'\n]]\n\nfinal_actions = final_actions.sort_values(by='max_recovery', ascending=False)\nfinal_actions.head(10)","metadata":{"_uuid":"b9620251-60bc-455f-a556-88d93ab57d51","_cell_guid":"92be8b57-70cb-4ca0-81d4-edb15a55d6bf","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:40:31.441022Z","iopub.execute_input":"2025-07-10T22:40:31.441386Z","iopub.status.idle":"2025-07-10T22:40:31.459479Z","shell.execute_reply.started":"2025-07-10T22:40:31.441362Z","shell.execute_reply":"2025-07-10T22:40:31.458245Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 32: Final SKU-Level Action Plan","metadata":{}},{"cell_type":"code","source":"def confidence_level(row):\n    if row['max_recovery'] > 3000 and row['margin_per_unit_x'] > 25:\n        return '🔵 High'\n    elif row['max_recovery'] > 1000:\n        return '🟡 Medium'\n    else:\n        return '🔴 Low'\n\nmerged_df['confidence'] = merged_df.apply(confidence_level, axis=1)","metadata":{"_uuid":"0f967a11-7c96-4970-b4e5-0275b4489021","_cell_guid":"518a7b7a-5824-4922-9a6f-e016f2927971","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:42:12.454499Z","iopub.execute_input":"2025-07-10T22:42:12.454919Z","iopub.status.idle":"2025-07-10T22:42:12.465983Z","shell.execute_reply.started":"2025-07-10T22:42:12.454890Z","shell.execute_reply":"2025-07-10T22:42:12.465001Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 33: SKU Removal Risk Assessment","metadata":{}},{"cell_type":"code","source":"def risk_score(row):\n    if row['purchases_x'] > 10 and row['view_to_buy_x'] > 0.03:\n        return '⚠️ High Risk to Remove'\n    elif row['purchases_x'] <= 2:\n        return '✅ Low Risk to Remove'\n    else:\n        return '🟡 Moderate Risk'\n\nmerged_df['removal_risk'] = merged_df.apply(risk_score, axis=1)","metadata":{"_uuid":"e778468a-8f07-48af-908b-a27fcfae752b","_cell_guid":"dc562213-271b-42d3-bb82-73a986ccc335","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:42:20.694549Z","iopub.execute_input":"2025-07-10T22:42:20.694866Z","iopub.status.idle":"2025-07-10T22:42:20.704565Z","shell.execute_reply.started":"2025-07-10T22:42:20.694844Z","shell.execute_reply":"2025-07-10T22:42:20.703098Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 34: Priority Scoring Engine","metadata":{}},{"cell_type":"code","source":"def priority_score(row):\n    score = 0\n    if row['action'].startswith('🔁'):\n        score += 40\n    if row['confidence'] == '🔵 High':\n        score += 30\n    if row['removal_risk'] == '✅ Low Risk to Remove':\n        score += 20\n    if row['max_recovery'] > 3000:\n        score += 10\n    return score\n\nmerged_df['priority_score'] = merged_df.apply(priority_score, axis=1)","metadata":{"_uuid":"79e5723f-10c3-4e18-8ef0-07399398094b","_cell_guid":"ada99083-2d8c-4985-bb62-63c49ac58043","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:42:28.875830Z","iopub.execute_input":"2025-07-10T22:42:28.876190Z","iopub.status.idle":"2025-07-10T22:42:28.887961Z","shell.execute_reply.started":"2025-07-10T22:42:28.876168Z","shell.execute_reply":"2025-07-10T22:42:28.886658Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 35: Final Executive SKU Action Playbook","metadata":{}},{"cell_type":"code","source":"executive_playbook = merged_df[[\n    'itemid', 'action', 'max_recovery', 'confidence',\n    'removal_risk', 'priority_score'\n]].sort_values(by='priority_score', ascending=False)\n\nexecutive_playbook.head(10)","metadata":{"_uuid":"fe854a81-40b6-42a0-b2bd-bf8d4c7ce987","_cell_guid":"d98f9ee2-d7f2-4d58-93f9-c103a6203b61","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:42:37.008635Z","iopub.execute_input":"2025-07-10T22:42:37.008968Z","iopub.status.idle":"2025-07-10T22:42:37.023978Z","shell.execute_reply.started":"2025-07-10T22:42:37.008944Z","shell.execute_reply":"2025-07-10T22:42:37.022953Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 36: Business Impact Simulation – Delay vs Inaction\n","metadata":{}},{"cell_type":"code","source":"# Assume promo delay = 15% loss in recovery, no action = 50% erosion growth\nmerged_df['recovery_if_now'] = merged_df['max_recovery']\nmerged_df['recovery_if_delayed'] = merged_df['max_recovery'] * 0.85\nmerged_df['loss_if_ignored'] = merged_df['max_recovery'] * 1.5","metadata":{"_uuid":"6ccf1793-16ff-4976-b878-aaac49bca23b","_cell_guid":"4f197b59-5907-450a-969a-4e27d22e6c41","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:45:03.794552Z","iopub.execute_input":"2025-07-10T22:45:03.795332Z","iopub.status.idle":"2025-07-10T22:45:03.800808Z","shell.execute_reply.started":"2025-07-10T22:45:03.795301Z","shell.execute_reply":"2025-07-10T22:45:03.799798Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 37: Trade-off Penalty Estimation","metadata":{}},{"cell_type":"code","source":"def tradeoff_penalty(row):\n    if row['action'].startswith('🔁'):\n        return round(row['purchases_x'] * 0.1, 1)  # assume 10% drop\n    else:\n        return 0\n\nmerged_df['expected_purchase_loss'] = merged_df.apply(tradeoff_penalty, axis=1)","metadata":{"_uuid":"512783b3-0950-47a9-b28f-bf3780122f6c","_cell_guid":"8525875b-7482-4879-aa70-6892011e0181","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:45:10.343471Z","iopub.execute_input":"2025-07-10T22:45:10.343833Z","iopub.status.idle":"2025-07-10T22:45:10.353650Z","shell.execute_reply.started":"2025-07-10T22:45:10.343811Z","shell.execute_reply":"2025-07-10T22:45:10.352271Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 38: Risk-Adjusted Recovery Score","metadata":{}},{"cell_type":"code","source":"# Map labels to weights\nconfidence_map = {'🔵 High': 1.0, '🟡 Medium': 0.75, '🔴 Low': 0.5}\nrisk_map = {'✅ Low Risk to Remove': 0.1, '🟡 Moderate Risk': 0.3, '⚠️ High Risk to Remove': 0.6}\n\nmerged_df['confidence_score'] = merged_df['confidence'].map(confidence_map)\nmerged_df['risk_score'] = merged_df['removal_risk'].map(risk_map)\n\n# Risk-adjusted recovery\nmerged_df['adjusted_recovery'] = merged_df['max_recovery'] * merged_df['confidence_score'] * (1 - merged_df['risk_score'])","metadata":{"_uuid":"1ad11ebc-9414-4070-90aa-99f9318e2d72","_cell_guid":"ee1180f8-0a65-490f-bd92-e579383837fc","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:45:18.760429Z","iopub.execute_input":"2025-07-10T22:45:18.760770Z","iopub.status.idle":"2025-07-10T22:45:18.770855Z","shell.execute_reply.started":"2025-07-10T22:45:18.760747Z","shell.execute_reply":"2025-07-10T22:45:18.769390Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 39: Final Strategic Action Table","metadata":{}},{"cell_type":"code","source":"final_strategy_table = merged_df[[\n    'itemid', 'action', 'max_recovery', 'confidence', 'removal_risk',\n    'expected_purchase_loss', 'adjusted_recovery', 'priority_score'\n]].sort_values(by='adjusted_recovery', ascending=False)\n\nfinal_strategy_table.head(10)","metadata":{"_uuid":"527884ef-82f5-4d86-96c2-1fd2d261e851","_cell_guid":"0a9b3e54-7f48-41a5-a258-7546965d1899","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:45:27.143906Z","iopub.execute_input":"2025-07-10T22:45:27.144256Z","iopub.status.idle":"2025-07-10T22:45:27.162893Z","shell.execute_reply.started":"2025-07-10T22:45:27.144230Z","shell.execute_reply":"2025-07-10T22:45:27.161699Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 40: Save & Confirm Final Output","metadata":{}},{"cell_type":"code","source":"# Save merged_df as CSV into the output folder\noutput_path = \"/kaggle/working/merged_strategy_dataset.csv\"\nmerged_df.to_csv(output_path, index=False)\n\n# Confirm it's saved by listing files\nimport os\nos.listdir(\"/kaggle/working\")","metadata":{"_uuid":"c64d2d7a-5509-4df6-80d0-1b37554dbaf0","_cell_guid":"1aaaf619-d7b1-4b0e-a3a6-d8218771343d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:48:37.430494Z","iopub.execute_input":"2025-07-10T22:48:37.430823Z","iopub.status.idle":"2025-07-10T22:48:37.451180Z","shell.execute_reply.started":"2025-07-10T22:48:37.430802Z","shell.execute_reply":"2025-07-10T22:48:37.449967Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 41: Save Final Strategy Dataset as CSV","metadata":{}},{"cell_type":"code","source":"# Save your final merged DataFrame to a downloadable CSV\nmerged_df.to_csv(\"/kaggle/working/merged_strategy_dataset.csv\", index=False)\n\n# Check if the file exists\nimport os\nprint(os.listdir(\"/kaggle/working\"))","metadata":{"_uuid":"16e70a9c-14e6-4608-b814-d36da150dfb1","_cell_guid":"6b059dc1-b93f-478a-bc97-577286c03432","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:49:27.300083Z","iopub.execute_input":"2025-07-10T22:49:27.300429Z","iopub.status.idle":"2025-07-10T22:49:27.318970Z","shell.execute_reply.started":"2025-07-10T22:49:27.300390Z","shell.execute_reply":"2025-07-10T22:49:27.317837Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 42: Classify Product Lifecycle Stages","metadata":{}},{"cell_type":"code","source":"# Step 1: Define lifecycle classification function\ndef classify_lifecycle(row):\n    if row['views_x'] < 300 and row['purchases_x'] == 0:\n        return '🍼 Early Stage'\n    elif row['purchases_x'] > 5 and row['erosion_flag'] == 0:\n        return '🚀 Growing'\n    elif row['erosion_flag'] == 1 and row['priority_score'] < 50:\n        return '🧊 Declining'\n    elif row['purchases_x'] == 0 and row['gross_margin'] == 0:\n        return '💀 Dead-weight'\n    else:\n        return '📦 Stable/Unclassified'\n\n# Step 2: Apply to your dataset\nmerged_df['lifecycle_stage'] = merged_df.apply(classify_lifecycle, axis=1)\n\n# Step 3: Group by lifecycle stage\nlifecycle_summary = merged_df.groupby('lifecycle_stage').agg(\n    sku_count=('itemid', 'count'),\n    total_margin=('gross_margin', 'sum'),\n    avg_priority_score=('priority_score', 'mean'),\n    avg_views=('views_x', 'mean'),\n    avg_margin_per_unit=('margin_per_unit_x', 'mean')\n).reset_index()\n\n# Step 4: Display\nlifecycle_summary","metadata":{"_uuid":"fde5d0c0-f0e1-4cf3-ac8d-baf923ccfd6e","_cell_guid":"621763c6-1255-4a20-9edb-44f0b1fdd2b7","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:56:04.382711Z","iopub.execute_input":"2025-07-10T22:56:04.383078Z","iopub.status.idle":"2025-07-10T22:56:04.433366Z","shell.execute_reply.started":"2025-07-10T22:56:04.383052Z","shell.execute_reply":"2025-07-10T22:56:04.431873Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 43: Final Executive Strategy Sheet","metadata":{}},{"cell_type":"code","source":"# Select and rename relevant columns\nexec_summary = merged_df[[\n    'itemid', 'action', 'adjusted_recovery', 'confidence', 'removal_risk',\n    'expected_purchase_loss', 'priority_score', 'lifecycle_stage'\n]].copy()\n\n# Rename columns for exec readability\nexec_summary.columns = [\n    'SKU ID', 'Recommended Action', 'Adjusted Recovery ($)', 'Confidence Level',\n    'Removal Risk', 'Expected Purchase Loss', 'Priority Score', 'Lifecycle Stage'\n]\n\n# Sort by Priority Score (high to low)\nexec_summary = exec_summary.sort_values(by='Priority Score', ascending=False).reset_index(drop=True)\n\n# Display summary\nexec_summary.head(20)  # or display the full DataFrame","metadata":{"_uuid":"64bb1451-0b5e-4694-a3e8-824066ae2e98","_cell_guid":"ecd76c3b-8d3c-416e-b154-b8965fba46c8","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:57:03.995019Z","iopub.execute_input":"2025-07-10T22:57:03.996102Z","iopub.status.idle":"2025-07-10T22:57:04.016503Z","shell.execute_reply.started":"2025-07-10T22:57:03.996051Z","shell.execute_reply":"2025-07-10T22:57:04.015275Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 44: Business Impact Simulator","metadata":{}},{"cell_type":"code","source":"# Simulate outcomes for different actions\nsimulator = exec_summary.copy()\n\n# Assume business logic for simulation:\n# Keep = no recovery\n# Cut Promo = adjusted recovery added to savings\n# Remove = adjusted recovery + expected_purchase_loss avoided\n\nsimulator['Simulated Margin Recovered ($)'] = simulator.apply(\n    lambda row: row['Adjusted Recovery ($)'] if 'Cut Promo' in row['Recommended Action'] else 0, axis=1\n)\n\n# Aggregate total recovery\ntotal_recovery = simulator['Simulated Margin Recovered ($)'].sum()\n\n# Optional: Breakdown by lifecycle\nimpact_by_stage = simulator.groupby('Lifecycle Stage')['Simulated Margin Recovered ($)'].sum().reset_index()\n\n# Show simulator results\nprint(\"💰 Total Margin Recovered if Actions Are Implemented: ${:,.2f}\".format(total_recovery))\nimpact_by_stage","metadata":{"_uuid":"ceb57625-1b72-4372-9300-13b7baacd9ba","_cell_guid":"268a42ea-7a46-4b0a-b5cc-be9448d0fbdb","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:57:29.457759Z","iopub.execute_input":"2025-07-10T22:57:29.458340Z","iopub.status.idle":"2025-07-10T22:57:29.475834Z","shell.execute_reply.started":"2025-07-10T22:57:29.458308Z","shell.execute_reply":"2025-07-10T22:57:29.474954Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"simulator = exec_summary.copy()\nsimulator['Simulated Margin Recovered ($)'] = simulator.apply(\n    lambda row: row['Adjusted Recovery ($)'] if 'Cut Promo' in row['Recommended Action'] else 0, axis=1\n)\ntotal_recovery = simulator['Simulated Margin Recovered ($)'].sum()\nimpact_by_stage = simulator.groupby('Lifecycle Stage')['Simulated Margin Recovered ($)'].sum().reset_index()","metadata":{"_uuid":"6be0dbae-604a-43c4-836f-6dc6101efe18","_cell_guid":"deb3b050-33d0-431a-b61d-7265b470df5f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T22:58:59.528994Z","iopub.execute_input":"2025-07-10T22:58:59.529874Z","iopub.status.idle":"2025-07-10T22:58:59.541450Z","shell.execute_reply.started":"2025-07-10T22:58:59.529839Z","shell.execute_reply":"2025-07-10T22:58:59.540214Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 45: Integrate Simulated Recovery into Executive Sheet","metadata":{}},{"cell_type":"code","source":"# Add the simulation column to the executive summary\nexec_summary['Simulated Margin Recovered ($)'] = simulator['Simulated Margin Recovered ($)']","metadata":{"_uuid":"7871f359-091d-42b7-972f-86a7d295dff1","_cell_guid":"5352cbb9-d032-4da3-b35e-72faa6e857eb","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T23:00:10.008822Z","iopub.execute_input":"2025-07-10T23:00:10.009196Z","iopub.status.idle":"2025-07-10T23:00:10.014436Z","shell.execute_reply.started":"2025-07-10T23:00:10.009168Z","shell.execute_reply":"2025-07-10T23:00:10.013352Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 46: Export Final Executive Strategy Sheet","metadata":{}},{"cell_type":"code","source":"exec_summary.to_csv(\"final_strategy_master_sheet.csv\", index=False)","metadata":{"_uuid":"bfcfed10-0cdd-42f7-9014-6cda6c81e619","_cell_guid":"9ad7556e-7076-47bc-9a10-4ea62194aba4","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T23:00:18.280964Z","iopub.execute_input":"2025-07-10T23:00:18.281709Z","iopub.status.idle":"2025-07-10T23:00:18.289935Z","shell.execute_reply.started":"2025-07-10T23:00:18.281681Z","shell.execute_reply":"2025-07-10T23:00:18.288936Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 47: Curate Top 5 High-Impact Erosion SKUs for Executive Summary","metadata":{}},{"cell_type":"code","source":"# Assign the data to a DataFrame named 'final_strategy_summary'\nfinal_strategy_summary = pd.DataFrame({\n    'itemid': [5411, 187946, 111530, 370653, 91755],\n    'views': [2325.0, 3410.0, 1397.0, 1854.0, 1024.0],\n    'purchases': [0.0, 0.0, 11.0, 0.0, 0.0],\n    'margin_per_unit': [38.57, 20.33, 38.30, 19.60, 30.06],\n    'view_to_buy': [0.0, 0.0, 0.007874, 0.0, 0.0],\n    'potential_extra_purchases': [65.640964, 96.273414, 28.441044, 52.343376, 28.910257],\n    'potential_margin_recovered': [2531.771998, 1957.238517, 1089.291985, 1025.930160, 869.042326]\n})","metadata":{"_uuid":"19674f59-c235-4514-8820-ff973fc7a359","_cell_guid":"a9a03226-5365-4d46-b183-08adbf15121a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T23:04:56.660475Z","iopub.execute_input":"2025-07-10T23:04:56.660877Z","iopub.status.idle":"2025-07-10T23:04:56.668912Z","shell.execute_reply.started":"2025-07-10T23:04:56.660850Z","shell.execute_reply":"2025-07-10T23:04:56.667897Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# This will show all your current DataFrame variables\nfor var_name in dir():\n    try:\n        if isinstance(eval(var_name), pd.DataFrame):\n            print(var_name)\n    except:\n        pass","metadata":{"_uuid":"cdc3c865-690e-4466-96b6-09540bb1e12f","_cell_guid":"7e9a46f8-e895-40a0-ac1b-12aa72793b54","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-10T23:05:33.676508Z","iopub.execute_input":"2025-07-10T23:05:33.677320Z","iopub.status.idle":"2025-07-10T23:05:33.685638Z","shell.execute_reply.started":"2025-07-10T23:05:33.677289Z","shell.execute_reply":"2025-07-10T23:05:33.684207Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  Step 49: Extract & Pivot Key Item Metadata for Enrichment","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Define properties you care about\nimportant_props = {'categoryid', 'brand', 'color', 'name'}\n\ndef load_important_properties(filepath, important_props, chunk_size=50000):\n    chunks = []\n    for chunk in pd.read_csv(filepath, chunksize=chunk_size):\n        chunk = chunk[chunk['property'].isin(important_props)]\n        chunks.append(chunk)\n    return pd.concat(chunks, ignore_index=True)\n\n# Load both item property parts\nprops1_filtered = load_important_properties('/kaggle/input/ecommerce-dataset/item_properties_part1.csv', important_props)\nprops2_filtered = load_important_properties('/kaggle/input/ecommerce-dataset/item_properties_part2.csv', important_props)\n\n# Combine and clean\nfiltered_props = pd.concat([props1_filtered, props2_filtered], ignore_index=True)\nfiltered_props['timestamp'] = pd.to_datetime(filtered_props['timestamp'])\n\n# Keep latest property value per (itemid, property)\nlatest_filtered = filtered_props.sort_values('timestamp').drop_duplicates(['itemid', 'property'], keep='last')\n\n# Pivot to wide format — each property becomes a column\nmetadata_df = latest_filtered.pivot(index='itemid', columns='property', values='value').reset_index()\n\n# View result\nmetadata_df.head()","metadata":{"_uuid":"59769fac-6e9a-47af-9bc9-237c17025bb5","_cell_guid":"fa3fa11a-bb47-48d5-914a-c9e090975b36","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-15T17:52:33.996252Z","iopub.execute_input":"2025-07-15T17:52:33.996563Z","iopub.status.idle":"2025-07-15T17:53:03.798676Z","shell.execute_reply.started":"2025-07-15T17:52:33.996538Z","shell.execute_reply":"2025-07-15T17:53:03.797811Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 50: Clean and Enrich Category Tree","metadata":{}},{"cell_type":"code","source":"# Load category tree safely\ncat_tree = pd.read_csv('/kaggle/input/ecommerce-dataset/category_tree.csv')\n\n# Check current columns\nprint(cat_tree.columns)\n\n# Rename them correctly — based on your file it looks like:\n# 1st col = itemid, 2nd col = categoryid\ncat_tree.columns = ['itemid', 'categoryid']\n\n# OPTIONAL: If you want to add a readable category name, you can later map this using a dictionary:\ncategory_map = {\n    '1038': 'Footwear',\n    '1171': 'Mobile Phones',\n    '1305': 'T-Shirts',\n    '1114': 'Headphones',\n    '209': 'Kitchenware',\n    # Add more if needed\n}\n\ncat_tree['category_name'] = cat_tree['categoryid'].astype(str).map(category_map)\n\ncat_tree.head()","metadata":{"_uuid":"23e51fdc-d06a-494f-8a30-12f3db45b859","_cell_guid":"3ef02e48-fd43-49c5-a6e5-e12dc98d212c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-15T17:54:14.737078Z","iopub.execute_input":"2025-07-15T17:54:14.737912Z","iopub.status.idle":"2025-07-15T17:54:14.755328Z","shell.execute_reply.started":"2025-07-15T17:54:14.737881Z","shell.execute_reply":"2025-07-15T17:54:14.754195Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 51: Identify Available Metadata Properties","metadata":{}},{"cell_type":"code","source":"# What properties are actually present?\nfiltered_props['property'].value_counts().head(20)","metadata":{"_uuid":"77121de8-1cee-4d2b-85d9-c18ad4ec560b","_cell_guid":"6cbafc92-5ce2-48ad-a43e-e1c4e7c8257e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-15T17:55:07.565595Z","iopub.execute_input":"2025-07-15T17:55:07.566360Z","iopub.status.idle":"2025-07-15T17:55:07.636116Z","shell.execute_reply.started":"2025-07-15T17:55:07.566330Z","shell.execute_reply":"2025-07-15T17:55:07.635366Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 52: Add Human-Readable Category Labels to Metadata","metadata":{}},{"cell_type":"code","source":"# Ensure categoryid is string\nmetadata_df['categoryid'] = metadata_df['categoryid'].astype(str)\n\n# Map human-readable category labels\ncategory_map = {\n    '213': 'Laptops',\n    '169': 'Electronics',\n    '9': 'Books',\n    '885': 'Men\\'s Clothing',\n    '1691': 'Mobiles',\n    '1038': 'Footwear',\n    '1171': 'Smartphones',\n    '1305': 'T-Shirts',\n    '1114': 'Headphones',\n    '209': 'Kitchenware',\n    # Add more as needed\n}\n\nmetadata_df['category_name'] = metadata_df['categoryid'].map(category_map)\n\n# Preview the cleaned metadata\nmetadata_df[['itemid', 'categoryid', 'category_name']].head()","metadata":{"_uuid":"2812ecd3-a5e0-4b42-a383-a58e5a748c58","_cell_guid":"91820217-8105-47fd-80a7-f7d6c5cd5404","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-15T17:55:30.765833Z","iopub.execute_input":"2025-07-15T17:55:30.766125Z","iopub.status.idle":"2025-07-15T17:55:30.910332Z","shell.execute_reply.started":"2025-07-15T17:55:30.766103Z","shell.execute_reply":"2025-07-15T17:55:30.909431Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 53: Load Sample Rows and Inspect Column Structures from Final Datasets","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Load only first few rows of each\nmerged_strategy = pd.read_csv('/kaggle/input/final-dataset/merged_strategy_dataset.csv', nrows=5)\nprofit_erosion = pd.read_csv('/kaggle/input/profit-erosion/profit_erosion_sku_analysis.csv', nrows=5)\nuplift_df = pd.read_csv('/kaggle/input/uplift-data/uplift_final.csv', nrows=5)\n\n# Show column names\nprint(\"Merged Strategy Columns:\\n\", merged_strategy.columns.tolist())\nprint(\"Profit Erosion Columns:\\n\", profit_erosion.columns.tolist())\nprint(\"Uplift Columns:\\n\", uplift_df.columns.tolist())","metadata":{"_uuid":"b07baa94-23d7-4ea8-ab57-024ff5a8bb9d","_cell_guid":"0379b587-1779-4501-b484-08c511d57089","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-15T18:00:46.538925Z","iopub.execute_input":"2025-07-15T18:00:46.539260Z","iopub.status.idle":"2025-07-15T18:00:46.577012Z","shell.execute_reply.started":"2025-07-15T18:00:46.539195Z","shell.execute_reply":"2025-07-15T18:00:46.576236Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 54: Enrich Strategy Dataset with Category Metadata","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Load merged strategy dataset\nmerged_strategy = pd.read_csv('/kaggle/input/final-dataset/merged_strategy_dataset.csv')\n\n# Ensure itemid is string in both\nmetadata_df['itemid'] = metadata_df['itemid'].astype(str)\nmerged_strategy['itemid'] = merged_strategy['itemid'].astype(str)\n\n# Merge on itemid to add category info\nenriched_df = merged_strategy.merge(\n    metadata_df[['itemid', 'categoryid', 'category_name']], \n    on='itemid', how='left'\n)\n\n# Preview key columns\nenriched_df[['itemid', 'views_x', 'purchases_x', 'margin_per_unit_x', 'category_name']].head()","metadata":{"_uuid":"05bf0f7e-c520-4a0f-b125-f7c2deaf3ac2","_cell_guid":"a0fa87c6-7722-4c5c-ad62-d86a77664077","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-15T18:01:12.303120Z","iopub.execute_input":"2025-07-15T18:01:12.303519Z","iopub.status.idle":"2025-07-15T18:01:12.529013Z","shell.execute_reply.started":"2025-07-15T18:01:12.303491Z","shell.execute_reply":"2025-07-15T18:01:12.528038Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 55: Extract and Pivot Category Metadata for Each SKU\n\n","metadata":{}},{"cell_type":"code","source":"# Step 1: Load important properties using smart chunking\nimport pandas as pd\n\nimportant_props = {'categoryid'}\n\ndef load_properties(filepath, props_to_keep):\n    chunks = []\n    for chunk in pd.read_csv(filepath, chunksize=50000):\n        chunk = chunk[chunk['property'].isin(props_to_keep)]\n        chunks.append(chunk)\n    return pd.concat(chunks, ignore_index=True)\n\nprops1 = load_properties('/kaggle/input/ecommerce-dataset/item_properties_part1.csv', important_props)\nprops2 = load_properties('/kaggle/input/ecommerce-dataset/item_properties_part2.csv', important_props)\n\nall_props = pd.concat([props1, props2])\nall_props['timestamp'] = pd.to_datetime(all_props['timestamp'])\n\n# Step 2: Keep latest property value for each itemid\nlatest_props = all_props.sort_values('timestamp').drop_duplicates(['itemid', 'property'], keep='last')\n\n# Step 3: Pivot categoryid into column\nmetadata_df = latest_props.pivot(index='itemid', columns='property', values='value').reset_index()\nmetadata_df['itemid'] = metadata_df['itemid'].astype(str)","metadata":{"_uuid":"d3bea555-7564-4d0b-ba92-24aa4f807f8c","_cell_guid":"90996b87-3135-4e85-97aa-8735ca55435f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-15T18:02:18.838840Z","iopub.execute_input":"2025-07-15T18:02:18.839147Z","iopub.status.idle":"2025-07-15T18:02:36.060260Z","shell.execute_reply.started":"2025-07-15T18:02:18.839126Z","shell.execute_reply":"2025-07-15T18:02:36.059307Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 56: Merge Category Metadata into Final Strategy Dataset","metadata":{}},{"cell_type":"code","source":"# Load main strategy dataset\nmerged_strategy = pd.read_csv('/kaggle/input/final-dataset/merged_strategy_dataset.csv')\nmerged_strategy['itemid'] = merged_strategy['itemid'].astype(str)\n\n# Merge category info\nenriched_df = merged_strategy.merge(metadata_df[['itemid', 'categoryid']], on='itemid', how='left')","metadata":{"_uuid":"c87ce840-569d-43e0-a1dd-02342360d40a","_cell_guid":"c1bea458-3c6b-4f16-8f6c-d0543d46bf65","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-15T18:02:50.660969Z","iopub.execute_input":"2025-07-15T18:02:50.661319Z","iopub.status.idle":"2025-07-15T18:02:50.847556Z","shell.execute_reply.started":"2025-07-15T18:02:50.661296Z","shell.execute_reply":"2025-07-15T18:02:50.846659Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 57: Map Category IDs to Readable Names","metadata":{}},{"cell_type":"code","source":"# Map readable names\ncategory_map = {\n    '213': 'Laptops', '169': 'Electronics', '9': 'Books',\n    '885': 'Men\\'s Clothing', '1691': 'Mobiles',\n    '1038': 'Footwear', '1171': 'Smartphones', '1305': 'T-Shirts',\n    '1114': 'Headphones', '209': 'Kitchenware'\n}\n\nenriched_df['category_name'] = enriched_df['categoryid'].astype(str).map(category_map)","metadata":{"_uuid":"6e3508ee-7a45-4995-881d-6bec96271f6a","_cell_guid":"1860c543-2e97-4532-aa28-49ebf8e89d45","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-15T18:03:01.620486Z","iopub.execute_input":"2025-07-15T18:03:01.620809Z","iopub.status.idle":"2025-07-15T18:03:01.628340Z","shell.execute_reply.started":"2025-07-15T18:03:01.620782Z","shell.execute_reply":"2025-07-15T18:03:01.627373Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 58: Check How Many Products Have Valid Category Names","metadata":{}},{"cell_type":"code","source":"# How many products now have a valid category_name?\nmatched = enriched_df['category_name'].notna().sum()\ntotal = len(enriched_df)\n\nprint(f\"✅ Category matched for {matched} out of {total} SKUs\")\n\n# Show sample of matched rows\nenriched_df[enriched_df['category_name'].notna()].head(10)","metadata":{"_uuid":"9c58369b-ad66-490d-90c0-0ff70c307f32","_cell_guid":"12c50138-14ad-4d5b-9c22-58844a75d278","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-15T18:03:31.395039Z","iopub.execute_input":"2025-07-15T18:03:31.395722Z","iopub.status.idle":"2025-07-15T18:03:31.416954Z","shell.execute_reply.started":"2025-07-15T18:03:31.395693Z","shell.execute_reply":"2025-07-15T18:03:31.415806Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 59: Extract Unique Item IDs from Strategy Dataset","metadata":{}},{"cell_type":"code","source":"# Get unique itemids from strategy dataset\nstrategy_items = merged_strategy['itemid'].astype(str).unique().tolist()","metadata":{"_uuid":"05be2de7-8daa-4fa0-863e-8682c14f565f","_cell_guid":"65794a26-dd0f-43a6-9696-4407c4ac9fae","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-15T18:04:01.673953Z","iopub.execute_input":"2025-07-15T18:04:01.674267Z","iopub.status.idle":"2025-07-15T18:04:01.679994Z","shell.execute_reply.started":"2025-07-15T18:04:01.674236Z","shell.execute_reply":"2025-07-15T18:04:01.678926Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 60: Load Relevant Properties Filtered by Item IDs and Property","metadata":{}},{"cell_type":"code","source":"important_props = {'categoryid'}\n\ndef load_relevant_properties(filepath, itemids, props_to_keep):\n    chunks = []\n    for chunk in pd.read_csv(filepath, chunksize=50000):\n        chunk = chunk[(chunk['property'].isin(props_to_keep)) & (chunk['itemid'].isin(itemids))]\n        chunks.append(chunk)\n    return pd.concat(chunks, ignore_index=True)\n\n# Load only relevant categoryid rows\nprops1 = load_relevant_properties('/kaggle/input/ecommerce-dataset/item_properties_part1.csv', strategy_items, important_props)\nprops2 = load_relevant_properties('/kaggle/input/ecommerce-dataset/item_properties_part2.csv', strategy_items, important_props)\n\nfiltered_props = pd.concat([props1, props2])\nfiltered_props['timestamp'] = pd.to_datetime(filtered_props['timestamp'])\n\n# Keep latest per item\nlatest = filtered_props.sort_values('timestamp').drop_duplicates(['itemid', 'property'], keep='last')\n\n# Pivot to get categoryid column\nmetadata_df = latest.pivot(index='itemid', columns='property', values='value').reset_index()\nmetadata_df['itemid'] = metadata_df['itemid'].astype(str)","metadata":{"_uuid":"d4dfcdbb-7369-4ae6-b1ea-e3dc7b32f074","_cell_guid":"0be91ef2-98e2-4049-bfe9-e7f82d39816f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-15T18:04:12.810959Z","iopub.execute_input":"2025-07-15T18:04:12.811299Z","iopub.status.idle":"2025-07-15T18:04:31.674892Z","shell.execute_reply.started":"2025-07-15T18:04:12.811274Z","shell.execute_reply":"2025-07-15T18:04:31.674122Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 61: Reload Filtered Properties with Correct Item ID Type and Show Sample\n","metadata":{}},{"cell_type":"code","source":"# Step 1: Define the filtering function again\ndef load_relevant_properties(filepath, itemids, props_to_keep):\n    chunks = []\n    for chunk in pd.read_csv(filepath, chunksize=50000):\n        chunk = chunk[(chunk['property'].isin(props_to_keep)) & (chunk['itemid'].isin(itemids))]\n        chunks.append(chunk)\n    return pd.concat(chunks, ignore_index=True)\n\n# Step 2: Extract itemids from your strategy dataset\nstrategy_items = merged_strategy['itemid'].astype(int).unique().tolist()  # Use int if original file uses int\n\n# Step 3: Now call the function properly\nimportant_props = {'categoryid'}\nprops1 = load_relevant_properties('/kaggle/input/ecommerce-dataset/item_properties_part1.csv', strategy_items, important_props)\nprops2 = load_relevant_properties('/kaggle/input/ecommerce-dataset/item_properties_part2.csv', strategy_items, important_props)\n\n# Step 4: Show what we got\nprint(\"Filtered rows from props1:\", len(props1))\nprint(\"Filtered rows from props2:\", len(props2))\nprint(\"Sample props1 rows:\\n\", props1.head())","metadata":{"_uuid":"1eb11399-d971-4796-925c-8ed80ae73f92","_cell_guid":"dea5bc11-7e36-4ea9-b1d6-fcceac69c28c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-15T18:06:31.733001Z","iopub.execute_input":"2025-07-15T18:06:31.733336Z","iopub.status.idle":"2025-07-15T18:06:48.494589Z","shell.execute_reply.started":"2025-07-15T18:06:31.733313Z","shell.execute_reply":"2025-07-15T18:06:48.493713Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 62: Combine Filtered Properties and Extract Latest Category per Item","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Combine and convert timestamp\nall_filtered = pd.concat([props1, props2])\nall_filtered['timestamp'] = pd.to_datetime(all_filtered['timestamp'], unit='ms')\n\n# Sort and drop duplicates to get latest categoryid per item\nlatest_props = all_filtered.sort_values('timestamp').drop_duplicates(['itemid'], keep='last')\n\n# Create metadata_df with itemid and categoryid\nmetadata_df = latest_props[['itemid', 'value']].rename(columns={'value': 'categoryid'})\nmetadata_df['itemid'] = metadata_df['itemid'].astype(str)","metadata":{"_uuid":"26a876d8-cf72-4ca7-9b8f-7286aba0c5f1","_cell_guid":"bd3a22cb-455d-48ff-bf0e-3ae6ec34056e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-15T18:07:32.422511Z","iopub.execute_input":"2025-07-15T18:07:32.422794Z","iopub.status.idle":"2025-07-15T18:07:32.444209Z","shell.execute_reply.started":"2025-07-15T18:07:32.422775Z","shell.execute_reply":"2025-07-15T18:07:32.443204Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## Step 63: Merge Category Data into Strategy Dataset","metadata":{}},{"cell_type":"code","source":"merged_strategy['itemid'] = merged_strategy['itemid'].astype(str)\n\n# Merge to get categoryid\nenriched_df = merged_strategy.merge(metadata_df, on='itemid', how='left')","metadata":{"_uuid":"4408eb8d-1f0d-4ed7-8909-a6fd24ff9b7e","_cell_guid":"edf30daa-3d66-4b89-ba5e-9478d6e299e0","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-15T18:07:40.293688Z","iopub.execute_input":"2025-07-15T18:07:40.294321Z","iopub.status.idle":"2025-07-15T18:07:40.302299Z","shell.execute_reply.started":"2025-07-15T18:07:40.294294Z","shell.execute_reply":"2025-07-15T18:07:40.301315Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 64: Map Category IDs to Readable Names\n\n","metadata":{}},{"cell_type":"code","source":"# Map readable names\ncategory_map = {\n    '213': 'Laptops', '169': 'Electronics', '9': 'Books',\n    '885': 'Men\\'s Clothing', '1691': 'Mobiles',\n    '1038': 'Footwear', '1171': 'Smartphones', '1305': 'T-Shirts',\n    '1114': 'Headphones', '209': 'Kitchenware', '238': 'Tablets',\n    '720': 'Fitness Gear', '819': 'Home Décor', '1613': 'Backpacks'\n}\n\nenriched_df['category_name'] = enriched_df['categoryid'].astype(str).map(category_map)\n\n# Check how many got matched\nprint(f\"✅ Category matched for {enriched_df['category_name'].notna().sum()} out of {len(enriched_df)} SKUs\")\n\n# Preview matched rows\nenriched_df[enriched_df['category_name'].notna()].head()","metadata":{"_uuid":"286b4c29-f56a-4ef8-b957-42c9f06c9d3f","_cell_guid":"fdb06edf-3c65-47cd-9039-f03ac04e02ec","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-15T18:07:48.698167Z","iopub.execute_input":"2025-07-15T18:07:48.699024Z","iopub.status.idle":"2025-07-15T18:07:48.724139Z","shell.execute_reply.started":"2025-07-15T18:07:48.698998Z","shell.execute_reply":"2025-07-15T18:07:48.723231Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 65: Aggregate and Summarize by Category","metadata":{}},{"cell_type":"code","source":"# Group by category to see cumulative impact\ncategory_summary = enriched_df[enriched_df['category_name'].notna()].groupby('category_name').agg(\n    sku_count=('itemid', 'count'),\n    total_views=('views_x', 'sum'),\n    total_purchases=('purchases_x', 'sum'),\n    avg_margin=('margin_per_unit_x', 'mean'),\n    total_recovery=('adjusted_recovery', 'sum'),\n    avg_priority=('priority_score', 'mean')\n).reset_index().sort_values(by='total_recovery', ascending=False)\n\ncategory_summary","metadata":{"_uuid":"d0e2c6c8-cdbc-4e60-8881-1b0e3c455124","_cell_guid":"e844ab5c-75bb-40eb-826f-bbf411c21084","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-15T18:08:41.281548Z","iopub.execute_input":"2025-07-15T18:08:41.281842Z","iopub.status.idle":"2025-07-15T18:08:41.354501Z","shell.execute_reply.started":"2025-07-15T18:08:41.281821Z","shell.execute_reply":"2025-07-15T18:08:41.353656Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 66: Prepare Executive SKU Strategy View","metadata":{}},{"cell_type":"code","source":"# Select and rename key columns for executive view\nsku_strategy = enriched_df[[\n    'itemid', 'views_x', 'purchases_x', 'margin_per_unit_x', 'view_to_buy_x',\n    'adjusted_recovery', 'priority_score', 'action', 'confidence', 'removal_risk'\n]].copy()\n\n# Rename for readability\nsku_strategy.columns = [\n    'SKU ID', 'Views', 'Purchases', 'Margin/Unit', 'View-to-Buy Rate',\n    'Adjusted Recovery ($)', 'Priority Score', 'Recommended Action',\n    'Confidence Level', 'Removal Risk'\n]\n\n# Sort by Priority Score + Recovery\nsku_strategy = sku_strategy.sort_values(by=['Priority Score', 'Adjusted Recovery ($)'], ascending=[False, False])\n\n# Display Top 10\nsku_strategy.head(10)","metadata":{"_uuid":"a3de8d61-1775-4f89-98ec-7d5a7256dab7","_cell_guid":"fdcd1b77-732d-43a6-8a73-6986d6fc2e00","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-15T18:10:05.557312Z","iopub.execute_input":"2025-07-15T18:10:05.558608Z","iopub.status.idle":"2025-07-15T18:10:05.581119Z","shell.execute_reply.started":"2025-07-15T18:10:05.558567Z","shell.execute_reply":"2025-07-15T18:10:05.580069Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 67: Format and finalize SKU strategy table for presentation","metadata":{}},{"cell_type":"code","source":"# Round key values for presentation\nsku_strategy['View-to-Buy Rate'] = sku_strategy['View-to-Buy Rate'].round(4)\nsku_strategy['Adjusted Recovery ($)'] = sku_strategy['Adjusted Recovery ($)'].round(2)\nsku_strategy['Margin/Unit'] = sku_strategy['Margin/Unit'].round(2)\n\n# Reorder columns for maximum clarity\nsku_strategy = sku_strategy[[\n    'SKU ID', 'Views', 'Purchases', 'Margin/Unit', 'View-to-Buy Rate',\n    'Adjusted Recovery ($)', 'Recommended Action', 'Confidence Level',\n    'Removal Risk', 'Priority Score'\n]]\n\n# Sort by priority and margin\nsku_strategy = sku_strategy.sort_values(by=['Priority Score', 'Adjusted Recovery ($)'], ascending=[False, False])\n\n# Preview final table\nsku_strategy.head(10)","metadata":{"_uuid":"0e4f421b-a650-4f3c-acd5-69b70e792338","_cell_guid":"4f63ec64-5541-466a-9d42-20c72c88048b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-15T18:10:56.319608Z","iopub.execute_input":"2025-07-15T18:10:56.319912Z","iopub.status.idle":"2025-07-15T18:10:56.341319Z","shell.execute_reply.started":"2025-07-15T18:10:56.319891Z","shell.execute_reply":"2025-07-15T18:10:56.340472Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 68: Simulate realistic pricing and cost data by category","metadata":{}},{"cell_type":"code","source":"# Example: Category-wise price rules (realistic estimates)\nprice_rules = {\n    'Headphones': (30, 150),\n    'Home Décor': (20, 100),\n    'Smartphones': (150, 1000),\n    'T-Shirts': (10, 40),\n    'Footwear': (25, 120),\n    'Backpacks': (20, 80),\n    'Kitchenware': (10, 60),\n    'Books': (5, 25)\n}\n\nimport numpy as np\n\n# Assign realistic prices based on category\ndef simulate_price(row):\n    cat = row['category_name']\n    if cat in price_rules:\n        return round(np.random.uniform(*price_rules[cat]), 2)\n    else:\n        return round(np.random.uniform(20, 80), 2)  # fallback\n\n# Apply pricing logic\nenriched_df['simulated_price'] = enriched_df.apply(simulate_price, axis=1)\nenriched_df['simulated_cost'] = (enriched_df['simulated_price'] * np.random.uniform(0.6, 0.8)).round(2)\nenriched_df['margin_per_unit'] = enriched_df['simulated_price'] - enriched_df['simulated_cost']","metadata":{"_uuid":"fe215fea-e928-49ed-b097-17fb6a59849d","_cell_guid":"aa5b88da-4a21-4bb2-9074-836166a6d38e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-15T18:12:29.804053Z","iopub.execute_input":"2025-07-15T18:12:29.804726Z","iopub.status.idle":"2025-07-15T18:12:29.817735Z","shell.execute_reply.started":"2025-07-15T18:12:29.804696Z","shell.execute_reply":"2025-07-15T18:12:29.816859Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 69: Train XGBoost classifier on profit erosion dataset and plot top feature importance\n","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier, plot_importance\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\n# Prepare data\nX = profit_erosion.drop(columns=['erosion_flag', 'itemid'])\ny = profit_erosion['erosion_flag']\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n\n# Fit model\nmodel = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\nmodel.fit(X_train, y_train)\n\n# Plot feature importance\nplt.figure(figsize=(10,6))\nplot_importance(model, importance_type='gain', max_num_features=10)\nplt.title(\"Top Features Influencing Erosion Risk\")\nplt.show()","metadata":{"_uuid":"ac93395f-8eef-49f3-a018-39e25d030bf5","_cell_guid":"97a28a97-3df1-4eba-84cc-c8436176c802","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-15T18:12:41.786661Z","iopub.execute_input":"2025-07-15T18:12:41.786941Z","iopub.status.idle":"2025-07-15T18:12:43.080090Z","shell.execute_reply.started":"2025-07-15T18:12:41.786922Z","shell.execute_reply":"2025-07-15T18:12:43.078681Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 70: Train Logistic Regression and plot feature importance with seaborn","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nmodel = LogisticRegression()\nmodel.fit(X, y)\n\ncoef_df = pd.DataFrame({\n    'Feature': X.columns,\n    'Importance': model.coef_[0]\n}).sort_values(by='Importance', key=abs, ascending=False)\n\nsns.barplot(data=coef_df, x='Importance', y='Feature')\nplt.title('Feature Importance from Logistic Regression')\nplt.show()","metadata":{"_uuid":"e76bb056-d5df-415a-8403-5dd436938c48","_cell_guid":"bf919bff-bac3-4fbe-bfb7-380cba6b8195","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-15T18:13:47.925842Z","iopub.execute_input":"2025-07-15T18:13:47.926140Z","iopub.status.idle":"2025-07-15T18:13:48.607102Z","shell.execute_reply.started":"2025-07-15T18:13:47.926117Z","shell.execute_reply":"2025-07-15T18:13:48.606051Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 71: Train XGBoost on full dataset and plot top feature importance\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom xgboost import XGBClassifier, plot_importance\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\n# Load full dataset\nprofit_erosion_full = pd.read_csv('/kaggle/input/profit-erosion/profit_erosion_sku_analysis.csv')\n\n# Drop rows with missing target\nprofit_erosion_full = profit_erosion_full.dropna(subset=['erosion_flag'])\n\n# Prepare features and labels\nX = profit_erosion_full.drop(columns=['erosion_flag', 'itemid'])\ny = profit_erosion_full['erosion_flag']\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n\n# Train model\nmodel = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\nmodel.fit(X_train, y_train)\n\n# Plot feature importance\nplt.figure(figsize=(10, 6))\nplot_importance(model, importance_type='gain', max_num_features=10)\nplt.title(\"Top Features Influencing Erosion Risk\")\nplt.show()","metadata":{"_uuid":"84e9217f-0b1c-4f53-aa09-7b840c808557","_cell_guid":"4ef3cc34-0dae-45a7-ad9c-407c409fb14b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-15T18:15:10.447944Z","iopub.execute_input":"2025-07-15T18:15:10.448452Z","iopub.status.idle":"2025-07-15T18:15:10.763744Z","shell.execute_reply.started":"2025-07-15T18:15:10.448428Z","shell.execute_reply":"2025-07-15T18:15:10.762817Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 72: Extract and export feature importance scores for Tableau visualization\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom xgboost import plot_importance\n\n# Get feature scores from the trained model\nimportance = model.get_booster().get_score(importance_type='gain')\n\n# Convert to DataFrame\nfeat_imp_df = pd.DataFrame.from_dict(importance, orient='index', columns=['importance']).reset_index()\nfeat_imp_df.columns = ['feature', 'importance']\n\n# Sort by importance\nfeat_imp_df = feat_imp_df.sort_values(by='importance', ascending=False)\n\n# Export to CSV for Tableau\nfeat_imp_df.to_csv('/kaggle/working/feature_importance_for_tableau.csv', index=False)\n\nfeat_imp_df.head(10)","metadata":{"_uuid":"5bf39362-cb7b-4579-b06b-5ea18e7bbe5e","_cell_guid":"456a0801-1beb-4f36-b5c1-b3e911d70fc6","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-15T18:16:20.474573Z","iopub.execute_input":"2025-07-15T18:16:20.474946Z","iopub.status.idle":"2025-07-15T18:16:20.501369Z","shell.execute_reply.started":"2025-07-15T18:16:20.474919Z","shell.execute_reply":"2025-07-15T18:16:20.500382Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Load all key datasets\nstrategy_df = pd.read_csv('/kaggle/input/final-dataset/merged_strategy_dataset.csv')\nuplift_df = pd.read_csv('/kaggle/input/uplift-data/uplift_final.csv')\nerosion_df = pd.read_csv('/kaggle/input/profit-erosion/profit_erosion_sku_analysis.csv')\n\n# Merge strategy + uplift\nmerged_df = strategy_df.merge(uplift_df, on='itemid', how='left', suffixes=('', '_uplift'))\n\n# Merge with erosion metrics\nmerged_df = merged_df.merge(erosion_df, on='itemid', how='left', suffixes=('', '_erosion'))\n\n# Drop duplicate columns\nmerged_df = merged_df.loc[:, ~merged_df.columns.duplicated()]\n\n# Export the final enriched dataset\nmerged_df.to_csv('/kaggle/working/final_enriched_strategy_dataset.csv', index=False)\n\nprint(\"✅ Final dataset saved with shape:\", merged_df.shape)\nmerged_df.head()","metadata":{"_uuid":"60316a48-b9e1-4bc1-8971-15fdcf4701ba","_cell_guid":"4264326b-4fc2-437e-bec5-22ef617ea9e3","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-15T18:17:58.017828Z","iopub.execute_input":"2025-07-15T18:17:58.018142Z","iopub.status.idle":"2025-07-15T18:17:58.078976Z","shell.execute_reply.started":"2025-07-15T18:17:58.018120Z","shell.execute_reply":"2025-07-15T18:17:58.078085Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"c=pd.read_csv(\"/kaggle/input/ecommerce-dataset/item_properties_part1.csv\")\nc.head()","metadata":{"_uuid":"97e7a209-9d52-4070-9b11-65f22584bc67","_cell_guid":"6f777e75-2d58-4a67-bdf3-6ddc723cb28d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 73: Merge all key datasets into one enriched master dataset","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom scipy.stats import chi2_contingency, mannwhitneyu\n\n# ✅ Step 1: Load the dataset\nevents = pd.read_csv('/kaggle/input/ecommerce-dataset/events.csv')\n\n# ✅ Step 2: Tag users who made a purchase as Group A (Exposed), rest as Group B (Control)\npurchase_users = set(events[events['event'] == 'transaction']['visitorid'])\nevents['group'] = events['visitorid'].apply(lambda x: 'A' if x in purchase_users else 'B')\n\n# ✅ Step 3: Aggregate metrics per visitor\nuser_metrics = events.groupby(['visitorid', 'group'])['event'].value_counts().unstack(fill_value=0).reset_index()\n\n# Add conversion flag\nuser_metrics['converted'] = user_metrics['transaction'] > 0\n\n# ✅ Step 4: Run Chi-Square Test for Conversion Rate\nconversion_table = pd.crosstab(user_metrics['group'], user_metrics['converted'])\nchi2, pval, _, _ = chi2_contingency(conversion_table)\n\nprint(\"🔍 A/B Test - Conversion Rate (Chi-Square)\")\nprint(conversion_table)\nprint(f\"Chi2 Stat: {chi2:.4f}, p-value: {pval:.4f}\")\nprint(f\"📌 Statistically Significant? {'Yes' if pval < 0.05 else 'No'}\")\n\n# ✅ Step 5: Mann-Whitney U Test for Views Per User\nviews_A = user_metrics[user_metrics['group'] == 'A']['view']\nviews_B = user_metrics[user_metrics['group'] == 'B']['view']\nstat, p = mannwhitneyu(views_A, views_B, alternative='two-sided')\n\nprint(\"\\n📊 A/B Test - Views Per User (Mann-Whitney U)\")\nprint(f\"Group A (Exposed) Avg Views: {views_A.mean():.2f}\")\nprint(f\"Group B (Control) Avg Views: {views_B.mean():.2f}\")\nprint(f\"U Stat: {stat:.4f}, p-value: {p:.4f}\")\nprint(f\"📌 Statistically Significant? {'Yes' if p < 0.05 else 'No'}\")","metadata":{"_uuid":"3e5ef1e9-5492-41e5-8246-62091e3fde20","_cell_guid":"a5c35918-0381-4409-a72f-340637522c77","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-17T03:42:31.258598Z","iopub.execute_input":"2025-07-17T03:42:31.258881Z","iopub.status.idle":"2025-07-17T03:42:36.060203Z","shell.execute_reply.started":"2025-07-17T03:42:31.258861Z","shell.execute_reply":"2025-07-17T03:42:36.059223Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 74: Perform A/B test analysis on user conversion and engagement\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom scipy.stats import chi2_contingency, mannwhitneyu, ttest_ind\n\n# Load your dataset\ndf = pd.read_csv('/kaggle/input/final-dataset/merged_strategy_dataset.csv')\n\n# Filter Groups\ngroup_A = df[df['action'] == '🔁 Cut Promo (C)']\ngroup_B = df[df['action'].isin(['⭕ No Action', None, ''])]\n\n# Sanity check\nprint(\"Group A (Promo-Cut):\", group_A.shape[0], \"SKUs\")\nprint(\"Group B (Control):\", group_B.shape[0], \"SKUs\")\n\nfrom scipy.stats import fisher_exact\n\n# Prepare contingency table\ncontingency = [[converted_A, not_converted_A],\n               [converted_B, not_converted_B]]\n\n# Use Fisher's Exact Test instead of Chi-Square\nodds_ratio, p_val_fisher = fisher_exact(contingency)\n\nprint(\"\\n🔍 A/B Test - Conversion Rate (Fisher's Exact)\")\nprint(f\"Converted A: {converted_A}, Converted B: {converted_B}\")\nprint(f\"Odds Ratio: {odds_ratio:.4f}, p-value: {p_val_fisher:.4f}\")\nprint(\"📌 Statistically Significant?\", \"Yes\" if p_val_fisher < 0.05 else \"No\")","metadata":{"_uuid":"a2307e3c-2e67-43d7-b225-88af4b2e8ef1","_cell_guid":"68f7f3dc-b03b-42f2-a995-e4c6633b5d4c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-17T03:46:59.952293Z","iopub.execute_input":"2025-07-17T03:46:59.952629Z","iopub.status.idle":"2025-07-17T03:46:59.973273Z","shell.execute_reply.started":"2025-07-17T03:46:59.952604Z","shell.execute_reply":"2025-07-17T03:46:59.972008Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport matplotlib.pyplot as plt\n\n# Load the dataset\ndf = pd.read_csv(\"/kaggle/input/final-dataset/merged_strategy_dataset.csv\")\n\n# Step 1: Define Features and Target\nfeatures = [\n    'views_x', 'add_to_cart', 'purchases_x', \n    'view_to_cart', 'cart_to_buy', 'view_to_buy_x',\n    'price', 'cost', 'margin_per_unit_x', 'gross_margin',\n    'confidence_score', 'priority_score'\n]\n\ntarget = 'adjusted_recovery'\n\n# Step 2: Drop rows with missing target\ndf_model = df.dropna(subset=[target])\n\n# Step 3: Train-Test Split\nX = df_model[features]\ny = df_model[target]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Step 4: Train Model\nmodel = GradientBoostingRegressor(random_state=42)\nmodel.fit(X_train, y_train)\n\n# Step 5: Predict\ny_pred = model.predict(X_test)\n\n# Step 6: Evaluation\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"✅ RMSE: {rmse:.2f}\")\nprint(f\"✅ R² Score: {r2:.2f}\")\n\n# Step 7: Feature Importance\nfeature_importance = pd.DataFrame({\n    'feature': features,\n    'importance': model.feature_importances_\n}).sort_values(by='importance', ascending=False)\n\nprint(\"\\n📊 Top Predictive Features:\")\nprint(feature_importance)\n\n# Optional: Save predictions to original dataframe\ndf['predicted_recovery'] = model.predict(df[features])\n\n# Optional: Export updated dataset\ndf.to_csv(\"final_with_predictions.csv\", index=False)\nprint(\"✅ File saved as final_with_predictions.csv\")","metadata":{"_uuid":"b40a9544-eb95-4e8c-b5d1-01af95eb3652","_cell_guid":"e2f7ba27-0182-4fc6-a6d2-05160f9bd7dc","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-17T03:51:01.965835Z","iopub.execute_input":"2025-07-17T03:51:01.966849Z","iopub.status.idle":"2025-07-17T03:51:02.739994Z","shell.execute_reply.started":"2025-07-17T03:51:01.966820Z","shell.execute_reply":"2025-07-17T03:51:02.739086Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 75: Generate smart strategic action recommendations based on priority, recovery, and confidence\n","metadata":{}},{"cell_type":"code","source":"# Step 1: Normalize priority and predicted recovery\ndf['norm_priority'] = (df['priority_score'] - df['priority_score'].min()) / (df['priority_score'].max() - df['priority_score'].min())\ndf['norm_predicted_recovery'] = (df['predicted_recovery'] - df['predicted_recovery'].min()) / (df['predicted_recovery'].max() - df['predicted_recovery'].min())\n\n# Step 2: Create Action Value Score (weighted)\ndf['action_value_score'] = (0.5 * df['norm_predicted_recovery']) + (0.3 * df['norm_priority']) + (0.2 * df['confidence_score'])\n\n# Step 3: Define Confidence Filter\ndf['filtered_confidence'] = df['confidence_score'].apply(lambda x: 1 if x >= 0.5 else 0)\n\n# Step 4: Smart Action Logic\ndef decide_action(row):\n    if row['filtered_confidence'] == 0:\n        return 'Ignore'\n    elif row['removal_risk'] == 1:\n        return 'Delay'\n    elif row['action_value_score'] > 0.7:\n        return 'Act Now'\n    elif row['action_value_score'] > 0.4:\n        return 'Cut'\n    else:\n        return 'Ignore'\n\ndf['smart_action'] = df.apply(decide_action, axis=1)\n\n# Step 5: Simulated Gain if Acted\ndf['expected_gain_if_act'] = df.apply(lambda row: row['predicted_recovery'] if row['smart_action'] == 'Act Now' else 0, axis=1)\n\n# Step 6: Save Updated File\ndf.to_csv(\"final_strategic_actions.csv\", index=False)\nprint(\"✅ Strategic action file saved: final_strategic_actions.csv\")\n\n# Optional: See counts\nprint(\"\\n📦 Action Breakdown:\")\nprint(df['smart_action'].value_counts())","metadata":{"_uuid":"c18a2869-ca80-4603-9022-ceb56984870d","_cell_guid":"7a05ce9f-6a4a-4177-9082-2fe794504ec1","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-17T03:51:53.129264Z","iopub.execute_input":"2025-07-17T03:51:53.129586Z","iopub.status.idle":"2025-07-17T03:51:53.164056Z","shell.execute_reply.started":"2025-07-17T03:51:53.129563Z","shell.execute_reply":"2025-07-17T03:51:53.163111Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}